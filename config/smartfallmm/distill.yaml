teacher_model: Models.experimental_cvtransformer.MMTransformer
model: Models.transformer.TransModel
dataset: smartfallmm

# train_subjects: 1
# test_subjects: [18]
#subjects: [1,2, 3, 4, 5,7,8,9, 10,11, 12,13,14,15, 16, 17, 18,47, 19,22,23]
subjects: [32,39,30,31,34,35,37,43,44,45,36,29]
#subjects: [1,2, 3, 4, 5,7,8,9, 10,11, 12,13,14,15, 16, 17, 18,47,29,30,31, 32, 34, 35, 36, 37,38,39, 40, 41, 42, 43,19,22,23,]

#model_args
teacher_args:
  acc_frames : 128
  num_joints : 32
  num_classes : 1
  spatial_embed : 32
  adepth : 2
  sdepth : 2
  num_heads : 2
  mocap_frames: 128
  num_patch: 2


model_args:
  num_layers : 2
  norm_first : True
  embed_dim: 32
  activation: relu 
  acc_coords : 3
  #acc_embed: 256
  #change num_classes to 8 for human activity recognition
  num_classes: 1
  acc_frames : 128
  mocap_frames : 128
  num_heads: 4

dataset_args: 
 mode: 'sliding_window'
 max_length: 128
 #change task to 'har' for Human activity recognition
 task : 'fd'
 modalities: ['skeleton', 'accelerometer']
 age_group: ['young']
 # change the sensor to phone , meta_wrist , meta_hip for experiments
 sensors: ['watch']
#optim
# weight_decay: 0.0004
# base_lr: 0.001


# training
batch_size: 64
test_batch_size: 64
val_batch_size : 64
num_epoch: 80

#dataloader
feeder: Feeder.Make_Dataset.UTD_mm

distill_loss: loss.SemanticLoss
distill_args: 
  T : 2
  alpha: 0.7

########
train_feeder_args:
  # npz_file: data/UTD_MAAD/utd_train_op_mf50_norm.npz
  batch_size: 64

val_feeder_args:
  # npz_file: data/UTD_MAAD/utd_val_op_mf50_norm.npz
  batch_size: 64

test_feeder_args: 
  # npz_file: data/UTD_MAAD/utd_test_op_mf50_norm.npz
  batch_size: 64

seed: 2 
optimizer: adamw
base_lr: 1e-3
weight_decay: 1e-4